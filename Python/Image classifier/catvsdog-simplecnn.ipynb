{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2 # load images \nfrom tensorflow import keras\nimport tensorflow as tf\n# Input data files are available in the read-only \"../input/\" directory\nfrom tqdm import tqdm \nfrom pathlib import Path\npwd = %pwd\npwd = Path(pwd)\nlist(pwd.iterdir())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T10:25:58.023642Z","iopub.execute_input":"2022-02-28T10:25:58.023967Z","iopub.status.idle":"2022-02-28T10:26:03.305938Z","shell.execute_reply.started":"2022-02-28T10:25:58.023938Z","shell.execute_reply":"2022-02-28T10:26:03.304945Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unzipping the Files","metadata":{}},{"cell_type":"code","source":"import zipfile as zp\nwith zp.ZipFile(\"/kaggle/input/dogs-vs-cats/test1.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zp.ZipFile(\"/kaggle/input/dogs-vs-cats/train.zip\",\"r\") as z:\n    z.extractall(\".\")","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:26:27.861751Z","iopub.execute_input":"2022-02-28T10:26:27.862034Z","iopub.status.idle":"2022-02-28T10:26:49.187697Z","shell.execute_reply.started":"2022-02-28T10:26:27.862005Z","shell.execute_reply":"2022-02-28T10:26:49.186663Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Locating file path","metadata":{}},{"cell_type":"code","source":"train_path = Path(pwd) / 'train'\nfor index,file_item in enumerate(train_path.iterdir()):\n    print(file_item)\n    if index == 4:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:26:49.193466Z","iopub.execute_input":"2022-02-28T10:26:49.194457Z","iopub.status.idle":"2022-02-28T10:26:49.237268Z","shell.execute_reply.started":"2022-02-28T10:26:49.194411Z","shell.execute_reply":"2022-02-28T10:26:49.236181Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Creating DataFrane for training ","metadata":{}},{"cell_type":"code","source":"img_data = pd.DataFrame(columns = ['path', 'labels'])\n# w = []\n# h = []\nfor i in tqdm(train_path.iterdir()):\n    idx = len(img_data.index)\n    img_data.loc[idx, 'path'] = str(i)\n    img_data.loc[idx,'labels'] =  str(i).split('/')[-1][:3]\n    img_shape = cv2.imread(str(i),0).shape\n#     w.append(img_shape[0])\n#     h.append(img_shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:26:49.240304Z","iopub.execute_input":"2022-02-28T10:26:49.240870Z","iopub.status.idle":"2022-02-28T10:27:54.225301Z","shell.execute_reply.started":"2022-02-28T10:26:49.240828Z","shell.execute_reply":"2022-02-28T10:27:54.224129Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Choosing image size","metadata":{}},{"cell_type":"code","source":"print(np.array(w).mean())\nprint(np.array(h).mean()) \n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T06:01:37.719437Z","iopub.execute_input":"2022-02-28T06:01:37.719728Z","iopub.status.idle":"2022-02-28T06:01:37.733836Z","shell.execute_reply.started":"2022-02-28T06:01:37.719683Z","shell.execute_reply":"2022-02-28T06:01:37.733056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"on an average values are between 360 to 400 So let's take 350 as it is close to both the values ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:27:54.227991Z","iopub.execute_input":"2022-02-28T10:27:54.228529Z","iopub.status.idle":"2022-02-28T10:27:55.213145Z","shell.execute_reply.started":"2022-02-28T10:27:54.228438Z","shell.execute_reply":"2022-02-28T10:27:55.211839Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Creating Generator for training","metadata":{}},{"cell_type":"code","source":"traning_generator = keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1./255,\n    horizontal_flip = True,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split = 0.2,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:27:55.214971Z","iopub.execute_input":"2022-02-28T10:27:55.215308Z","iopub.status.idle":"2022-02-28T10:27:55.226776Z","shell.execute_reply.started":"2022-02-28T10:27:55.215263Z","shell.execute_reply":"2022-02-28T10:27:55.225032Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Defining Flow for training","metadata":{}},{"cell_type":"code","source":"train_generator = traning_generator.flow_from_dataframe(\n    dataframe = img_data,\n     x_col='path',\n    y_col='labels',\n    target_size=(350, 350),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset= 'training'\n)\n\nval_generator = traning_generator.flow_from_dataframe(\n    dataframe = img_data,\n     x_col='path',\n    y_col='labels',\n    target_size=(350, 350),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset= 'validation'\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:27:55.228200Z","iopub.execute_input":"2022-02-28T10:27:55.228501Z","iopub.status.idle":"2022-02-28T10:27:55.719147Z","shell.execute_reply.started":"2022-02-28T10:27:55.228459Z","shell.execute_reply":"2022-02-28T10:27:55.717919Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Initializing ImageDataGenerator","metadata":{}},{"cell_type":"code","source":"traning_generator = keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1./255,\n    horizontal_flip = True,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split = 0.2,\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:27:55.720917Z","iopub.execute_input":"2022-02-28T10:27:55.721494Z","iopub.status.idle":"2022-02-28T10:27:55.728466Z","shell.execute_reply.started":"2022-02-28T10:27:55.721448Z","shell.execute_reply":"2022-02-28T10:27:55.727016Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_generator = traning_generator.flow_from_dataframe(\n    dataframe = img_data,\n     x_col='path',\n    y_col='labels',\n    target_size=(350, 350),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=64,\n    shuffle=True,\n    seed=42,\n    subset= 'training'\n)\n\nval_generator = traning_generator.flow_from_dataframe(\n    dataframe = img_data,\n     x_col='path',\n    y_col='labels',\n    target_size=(350, 350),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=64,\n    shuffle=True,\n    seed=42,\n    subset= 'validation'\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:27:55.730180Z","iopub.execute_input":"2022-02-28T10:27:55.730860Z","iopub.status.idle":"2022-02-28T10:27:56.202196Z","shell.execute_reply.started":"2022-02-28T10:27:55.730814Z","shell.execute_reply":"2022-02-28T10:27:56.201074Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Model Creation Step","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:27:56.203747Z","iopub.execute_input":"2022-02-28T10:27:56.204021Z","iopub.status.idle":"2022-02-28T10:27:56.209414Z","shell.execute_reply.started":"2022-02-28T10:27:56.203979Z","shell.execute_reply":"2022-02-28T10:27:56.208150Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense,Conv2D,GlobalAveragePooling2D,Flatten,Dropout,MaxPool2D","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:27:56.213557Z","iopub.execute_input":"2022-02-28T10:27:56.214210Z","iopub.status.idle":"2022-02-28T10:27:56.222320Z","shell.execute_reply.started":"2022-02-28T10:27:56.214158Z","shell.execute_reply":"2022-02-28T10:27:56.221349Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = keras.models.Sequential()\n\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(350,350,3),activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(GlobalAveragePooling2D())\n\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy'],\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T14:49:27.685943Z","iopub.execute_input":"2022-02-28T14:49:27.686217Z","iopub.status.idle":"2022-02-28T14:49:27.705418Z","shell.execute_reply.started":"2022-02-28T14:49:27.686186Z","shell.execute_reply":"2022-02-28T14:49:27.704441Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model.fit(\n    train_generator,\n    validation_data = val_generator,\n    epochs = 20,\n    callbacks = [\n                 keras.callbacks.EarlyStopping(\n                     monitor = 'val_loss',\n                     patience = 5,\n                     restore_best_weights = True\n                 ),\n\n                 keras.callbacks.ReduceLROnPlateau(\n                      monitor='val_loss',\n                      patience=3\n                )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T10:29:56.458708Z","iopub.execute_input":"2022-02-28T10:29:56.459116Z","iopub.status.idle":"2022-02-28T14:25:23.166531Z","shell.execute_reply.started":"2022-02-28T10:29:56.459059Z","shell.execute_reply":"2022-02-28T14:25:23.165386Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"results = model.evaluate(test_generator, verbose=0)\n\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = (model.predict(test_generator) >= 0.5).astype(np.int)\n\ncm = confusion_matrix(test_generator.labels, predictions, labels=[0, 1])\nclr = classification_report(test_generator.labels, predictions, labels=[0, 1], target_names=[\"CAT\", \"DOG\"])\n\nplt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks=[0.5, 1.5], labels=[\"CAT\", \"DOG\"])\nplt.yticks(ticks=[0.5, 1.5], labels=[\"CAT\", \"DOG\"])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{},"execution_count":null,"outputs":[]}]}